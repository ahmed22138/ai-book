"use strict";(self.webpackChunkai_textbook_frontend=self.webpackChunkai_textbook_frontend||[]).push([[68],{5877:function(n,e,t){t.r(e),t.d(e,{assets:function(){return l},contentTitle:function(){return a},default:function(){return h},frontMatter:function(){return o},metadata:function(){return s},toc:function(){return c}});var s=JSON.parse('{"id":"control/week-9-mobile-navigation","title":"Week 9: Mobile Robot Navigation","description":"Putting It All Together","source":"@site/docs/03-control/week-9-mobile-navigation.mdx","sourceDirName":"03-control","slug":"/control/week-9-mobile-navigation","permalink":"/ai-textbook/docs/control/week-9-mobile-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/ai-textbook/tree/main/docs/03-control/week-9-mobile-navigation.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Week 8: Trajectory Planning & Collision Avoidance","permalink":"/ai-textbook/docs/control/week-8-trajectory-planning"},"next":{"title":"Week 10: Learning from Data & Imitation Learning","permalink":"/ai-textbook/docs/integration/week-10-learning"}}'),i=t(4848),r=t(8453);const o={sidebar_position:3},a="Week 9: Mobile Robot Navigation",l={},c=[{value:"Putting It All Together",id:"putting-it-all-together",level:2},{value:"Part 1: Complete Navigation Stack",id:"part-1-complete-navigation-stack",level:2},{value:"Complete Navigation System",id:"complete-navigation-system",level:3},{value:"Part 2: Behavior-Based Navigation",id:"part-2-behavior-based-navigation",level:2},{value:"Part 3: Performance Metrics",id:"part-3-performance-metrics",level:2},{value:"Real-World Deployment Checklist",id:"real-world-deployment-checklist",level:2},{value:"Week 9 Learning Outcomes",id:"week-9-learning-outcomes",level:2},{value:"Key Terminology",id:"key-terminology",level:2},{value:"Discussion Questions",id:"discussion-questions",level:2},{value:"Hands-On Activity",id:"hands-on-activity",level:2},{value:"Resources for Deeper Learning",id:"resources-for-deeper-learning",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"week-9-mobile-robot-navigation",children:"Week 9: Mobile Robot Navigation"})}),"\n",(0,i.jsx)(e.h2,{id:"putting-it-all-together",children:"Putting It All Together"}),"\n",(0,i.jsxs)(e.p,{children:["Weeks 7-8 covered the individual components. This week, we integrate them into a complete ",(0,i.jsx)(e.strong,{children:"autonomous navigation system"})," that plans, follows trajectories, and reacts to obstacles in real-time."]}),"\n",(0,i.jsx)(e.h2,{id:"part-1-complete-navigation-stack",children:"Part 1: Complete Navigation Stack"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"User Goal (x, y)\n     \u2193\n[PERCEPTION LAYER]\n  SLAM: Localization + Mapping\n  \u2192 Robot pose estimate\n  \u2192 Local occupancy grid\n     \u2193\n[PLANNING LAYER]\n  Path Planning: Find collision-free path\n  \u2192 Waypoint sequence\n     \u2193\n[CONTROL LAYER]\n  Trajectory Planning: Add timing\n  Collision Avoidance: React to obstacles\n  \u2192 Velocity commands (v, \u03c9)\n     \u2193\n[EXECUTION LAYER]\n  Motor Control: Apply commands\n  \u2192 Wheel speeds, steering angles\n     \u2193\nRobot Movement\n"})}),"\n",(0,i.jsx)(e.h3,{id:"complete-navigation-system",children:"Complete Navigation System"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class AutonomousNavigator:\n    def __init__(self):\n        # Perception\n        self.slam = SimpleSLAM()\n        self.occupancy_grid = OccupancyGrid(width=50, height=50)\n\n        # Planning\n        self.path_planner = AStarPlanner()\n        self.trajectory_planner = TrajectoryPlanner()\n\n        # Control\n        self.collision_avoider = DynamicWindowApproach()\n        self.odometry = RobotOdometry()\n\n        # State\n        self.current_goal = None\n        self.current_path = None\n        self.path_index = 0\n        self.last_replan_time = 0\n        self.replan_interval = 1.0  # Replan every 1 second\n\n    def navigate(self, goal_x, goal_y, sensors, dt=0.05):\n        \"\"\"Main navigation loop (20 Hz)\"\"\"\n\n        # 1. PERCEPTION: Update pose and map\n        pose, map_grid = self.update_perception(sensors, dt)\n\n        # 2. PLANNING: Compute or update path\n        if self.path_needs_replanning(pose, map_grid):\n            self.current_path = self.path_planner.plan(\n                pose[:2], (goal_x, goal_y), map_grid\n            )\n            self.path_index = 0\n            self.last_replan_time = time.time()\n\n        # 3. CONTROL: Compute velocity command\n        if self.current_path:\n            next_waypoint = self.current_path[self.path_index]\n\n            # Get velocity that:\n            # - Follows the path\n            # - Avoids obstacles\n            # - Respects acceleration limits\n\n            v_cmd = self.collision_avoider.compute_velocity_command(\n                pose, next_waypoint, sensors['obstacles']\n            )\n\n            # Check if waypoint reached\n            distance_to_waypoint = np.linalg.norm(\n                np.array(next_waypoint) - np.array(pose[:2])\n            )\n\n            if distance_to_waypoint < 0.2:  # Within 20cm\n                self.path_index += 1\n\n            # Check if goal reached\n            distance_to_goal = np.linalg.norm(\n                np.array([goal_x, goal_y]) - np.array(pose[:2])\n            )\n\n            if distance_to_goal < 0.3:\n                return 'goal_reached', (0, 0)\n\n            return 'navigating', v_cmd\n\n        else:\n            return 'no_path', (0, 0)\n\n    def update_perception(self, sensors, dt):\n        \"\"\"Update SLAM and get current estimate\"\"\"\n\n        lidar_scan = sensors['lidar']\n        left_encoder = sensors['encoders']['left']\n        right_encoder = sensors['encoders']['right']\n\n        # Update SLAM\n        pose = self.slam.step(left_encoder, right_encoder, lidar_scan)\n\n        # Get current map\n        map_grid = self.slam.occupancy_grid\n\n        return pose, map_grid\n\n    def path_needs_replanning(self, current_pose, map_grid):\n        \"\"\"Check if path is still valid\"\"\"\n\n        time_since_replan = time.time() - self.last_replan_time\n\n        if time_since_replan > self.replan_interval:\n            return True\n\n        if self.current_path is None:\n            return True\n\n        # Check if current path hits new obstacles\n        for waypoint in self.current_path:\n            if not map_grid.is_occupancy_free(waypoint[0], waypoint[1]):\n                return True\n\n        return False\n"})}),"\n",(0,i.jsx)(e.h2,{id:"part-2-behavior-based-navigation",children:"Part 2: Behavior-Based Navigation"}),"\n",(0,i.jsxs)(e.p,{children:["For complex scenarios, use ",(0,i.jsx)(e.strong,{children:"behavior hierarchies"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class BehaviorTree:\n    def __init__(self):\n        self.behaviors = {\n            \'reach_goal\': self.reach_goal,\n            \'avoid_obstacle\': self.avoid_obstacle,\n            \'get_unstuck\': self.get_unstuck,\n            \'idle\': self.idle\n        }\n\n        self.stuck_timer = 0\n        self.last_pose = None\n\n    def execute(self, robot_state, sensors):\n        """Execute behavior tree"""\n\n        # Priority-based execution\n        # Try behaviors in order, use first that returns valid command\n\n        # Highest priority: Avoid immediate collision\n        if self.is_in_danger(sensors):\n            return self.avoid_obstacle(robot_state, sensors)\n\n        # Check if stuck\n        if self.is_stuck(robot_state):\n            return self.get_unstuck(robot_state, sensors)\n\n        # Normal operation: reach goal\n        if robot_state[\'goal\'] is not None:\n            return self.reach_goal(robot_state, sensors)\n\n        # Nothing to do\n        return self.idle()\n\n    def is_in_danger(self, sensors):\n        """Check for imminent collision"""\n        min_distance = np.min([obs[\'distance\'] for obs in sensors[\'obstacles\']])\n        return min_distance < 0.3  # Less than 30cm\n\n    def avoid_obstacle(self, robot_state, sensors):\n        """Emergency obstacle avoidance"""\n        # Find clear direction\n        for angle in np.linspace(-np.pi, np.pi, 16):\n            direction = (np.cos(angle), np.sin(angle))\n\n            if self.direction_clear(sensors, direction):\n                return (0.5, 0.5 * angle)  # Move and turn\n\n        return (0, 1.0)  # Spin in place if trapped\n\n    def is_stuck(self, robot_state):\n        """Detect if robot is stuck"""\n        if self.last_pose is None:\n            self.last_pose = robot_state[\'pose\']\n            return False\n\n        movement = np.linalg.norm(\n            np.array(robot_state[\'pose\'][:2]) -\n            np.array(self.last_pose[:2])\n        )\n\n        if movement < 0.01:  # Less than 1cm movement\n            self.stuck_timer += 1\n        else:\n            self.stuck_timer = 0\n\n        self.last_pose = robot_state[\'pose\']\n\n        return self.stuck_timer > 30  # Stuck for 1.5 seconds\n\n    def get_unstuck(self, robot_state, sensors):\n        """Recover from stuck state"""\n        return (-0.5, 1.0)  # Back up and turn\n\n    def reach_goal(self, robot_state, sensors):\n        """Navigate to goal"""\n        # Use path planning + collision avoidance\n        # (Calls methods from AutonomousNavigator)\n        pass\n\n    def idle(self):\n        """Do nothing"""\n        return (0, 0)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"part-3-performance-metrics",children:"Part 3: Performance Metrics"}),"\n",(0,i.jsx)(e.p,{children:"How do we measure navigation quality?"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class NavigationMetrics:\n    @staticmethod\n    def path_length(path):\n        """Total distance traveled"""\n        length = 0\n        for i in range(1, len(path)):\n            length += np.linalg.norm(\n                np.array(path[i]) - np.array(path[i-1])\n            )\n        return length\n\n    @staticmethod\n    def success_rate(trials):\n        """Percentage of successful navigations"""\n        successful = sum(1 for trial in trials if trial[\'reached_goal\'])\n        return successful / len(trials) * 100\n\n    @staticmethod\n    def average_time(trials):\n        """Average time to reach goal"""\n        successful_trials = [t for t in trials if t[\'reached_goal\']]\n        times = [t[\'time_taken\'] for t in successful_trials]\n        return np.mean(times) if times else float(\'inf\')\n\n    @staticmethod\n    def smoothness(path):\n        """Measure path smoothness (lower = smoother)"""\n        angles = []\n\n        for i in range(1, len(path)-1):\n            v1 = np.array(path[i]) - np.array(path[i-1])\n            v2 = np.array(path[i+1]) - np.array(path[i])\n\n            angle = np.arccos(\n                np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n            )\n            angles.append(angle)\n\n        return np.std(angles)  # Standard deviation of turning angles\n\n    @staticmethod\n    def clearance(path, obstacles, min_margin=0.2):\n        """Minimum clearance from obstacles"""\n        min_clearance = float(\'inf\')\n\n        for pose in path:\n            for obs in obstacles:\n                distance = np.linalg.norm(\n                    np.array(pose) - np.array(obs[\'position\'])\n                ) - obs[\'radius\']\n\n                min_clearance = min(min_clearance, distance)\n\n        return max(0, min_clearance - min_margin)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"real-world-deployment-checklist",children:"Real-World Deployment Checklist"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class NavigationValidator:\n    @staticmethod\n    def validate_navigation_system():\n        \"\"\"Checklist before real robot deployment\"\"\"\n\n        checks = {\n            'perception': {\n                'slam_accuracy': self.test_slam_accuracy(),\n                'map_quality': self.test_map_quality(),\n                'localization_drift': self.test_drift(),\n            },\n            'planning': {\n                'path_feasibility': self.test_paths_feasible(),\n                'computation_time': self.test_planner_speed(),\n                'completeness': self.test_completeness(),\n            },\n            'control': {\n                'collision_avoidance': self.test_collision_avoidance(),\n                'tracking_accuracy': self.test_trajectory_tracking(),\n                'response_time': self.test_response_latency(),\n            },\n            'integration': {\n                'end_to_end': self.test_end_to_end(),\n                'failure_modes': self.test_failure_recovery(),\n                'long_term_stability': self.test_long_duration(),\n            }\n        }\n\n        all_pass = all(\n            all(v for v in category.values())\n            for category in checks.values()\n        )\n\n        return all_pass, checks\n"})}),"\n",(0,i.jsx)(e.h2,{id:"week-9-learning-outcomes",children:"Week 9 Learning Outcomes"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this week, you should be able to:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Integrate"})," perception, planning, and control into single system"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Design"})," behavior hierarchies for complex navigation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Measure"})," navigation performance (success rate, path length, smoothness)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Debug"})," navigation failures (stuck detection, replanning)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Deploy"})," navigation to real robots safely"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Validate"})," system before field deployment"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"key-terminology",children:"Key Terminology"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Term"}),(0,i.jsx)(e.th,{children:"Definition"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Navigation stack"})}),(0,i.jsx)(e.td,{children:"Complete system: perception \u2192 planning \u2192 control"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Behavior tree"})}),(0,i.jsx)(e.td,{children:"Hierarchical decision structure for complex tasks"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Stuck detection"})}),(0,i.jsx)(e.td,{children:"Recognizing when robot makes no progress"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Replanning"})}),(0,i.jsx)(e.td,{children:"Recomputing path when obstacles block original path"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Clearance"})}),(0,i.jsx)(e.td,{children:"Minimum distance to obstacles along path"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Success rate"})}),(0,i.jsx)(e.td,{children:"Percentage of navigation attempts that reach goal"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Latency"})}),(0,i.jsx)(e.td,{children:"Delay between sensing and control command"})]})]})]}),"\n",(0,i.jsx)(e.h2,{id:"discussion-questions",children:"Discussion Questions"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Safety"}),": A robot navigates near humans. How would you ensure safe behavior?"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Failure modes"}),": List 5 ways navigation could fail (sensor failure, stuck, etc.). How do you detect and recover from each?"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Real-time constraints"}),": Navigation must run at 20 Hz (50ms per cycle). Where would you optimize?"]}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Scalability"}),": Does the stack scale to large warehouses or complex urban environments?"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"hands-on-activity",children:"Hands-On Activity"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Test navigation in simulation"})}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Use Gazebo/ROS simulator with mobile robot"}),"\n",(0,i.jsx)(e.li,{children:"Create warehouse environment with obstacles"}),"\n",(0,i.jsx)(e.li,{children:"Command robot to 10 different goals"}),"\n",(0,i.jsx)(e.li,{children:"Measure for each: time, path length, success/failure"}),"\n",(0,i.jsx)(e.li,{children:"Report average metrics"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"resources-for-deeper-learning",children:"Resources for Deeper Learning"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Framework"}),": ROS Navigation Stack - free, industry standard"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Course"}),': "Mobile Robots" - UC Berkeley']}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Simulator"}),": Gazebo - free physics simulator"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Paper"}),': "The Dynamic Window Approach to Collision Avoidance" - Fox et al.']}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Tool"}),": RViz - ROS visualization"]}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Next"}),": Module 4 - Integration & Advanced Topics"]}),"\n",(0,i.jsxs)(e.p,{children:["\ud83d\udca1 ",(0,i.jsx)(e.strong,{children:"Tip"}),": Always test your navigation stack in simulation before deploying to a real robot!"]})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:function(n,e,t){t.d(e,{R:function(){return o},x:function(){return a}});var s=t(6540);const i={},r=s.createContext(i);function o(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:o(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);